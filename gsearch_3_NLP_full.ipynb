{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting skills from job description\n",
    "Function will return nested dict (see NLP_skillNer_example)\n",
    "\n",
    "!NOTE: The extraction is a very long process. 500 jobs can take multiple hours. \n",
    "\n",
    "There are errors in specific rows. Solved beneath \"return None\" and with a \"for loop and continue\" beneath\n",
    "If you want the dictionnaires for each row as a column of the df, run cell below with the function \"skills\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports SKILLNER\n",
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "# load default skills data base\n",
    "from skillNer.general_params import SKILL_DB # EMSI skills database \n",
    "# import skill extractor\n",
    "from skillNer.skill_extractor_class import SkillExtractor\n",
    "\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = pd.read_csv(\"data/gsearch_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>via</th>\n",
       "      <th>description</th>\n",
       "      <th>extensions</th>\n",
       "      <th>schedule_type</th>\n",
       "      <th>work_from_home</th>\n",
       "      <th>...</th>\n",
       "      <th>python</th>\n",
       "      <th>sql</th>\n",
       "      <th>tableau</th>\n",
       "      <th>bi tool</th>\n",
       "      <th>power bi</th>\n",
       "      <th>aws</th>\n",
       "      <th>azure</th>\n",
       "      <th>excel</th>\n",
       "      <th>powerpoint</th>\n",
       "      <th>r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>Cisco Meraki</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>via linkedin</td>\n",
       "      <td>as the leader in cloud-managed it, cisco merak...</td>\n",
       "      <td>['22 hours ago', 'Work from home', 'Full-time'...</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>entry level - business data analyst (remote)</td>\n",
       "      <td>Midwest Staffing</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>via linkedin</td>\n",
       "      <td>as a senior business analyst you will contribu...</td>\n",
       "      <td>['53 minutes ago', 'Work from home', 'Full-tim...</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>data analyst/researcher</td>\n",
       "      <td>Amyx, Inc.</td>\n",
       "      <td>United States</td>\n",
       "      <td>via indeed</td>\n",
       "      <td>overview:\\n\\namyx is seeking to hire a data an...</td>\n",
       "      <td>['3 hours ago', 'Full-time']</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>data analyst/ai expert to help build a website...</td>\n",
       "      <td>Upwork</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>via upwork</td>\n",
       "      <td>i am looking for someone to help me build an a...</td>\n",
       "      <td>['23 hours ago', 'Work from home', 'Contractor']</td>\n",
       "      <td>Contractor</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>Bank Street College of Education</td>\n",
       "      <td>United States</td>\n",
       "      <td>via higher education recruitment consortium (h...</td>\n",
       "      <td>position vacancy – data analyst to support the...</td>\n",
       "      <td>['20 hours ago', 'Full-time']</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index                                              title  \\\n",
       "0           0      0                                       data analyst   \n",
       "1           1      1       entry level - business data analyst (remote)   \n",
       "2           2      2                            data analyst/researcher   \n",
       "3           3      3  data analyst/ai expert to help build a website...   \n",
       "4           4      4                                       data analyst   \n",
       "\n",
       "                       company_name            location  \\\n",
       "0                      Cisco Meraki           Anywhere    \n",
       "1                  Midwest Staffing           Anywhere    \n",
       "2                        Amyx, Inc.    United States      \n",
       "3                            Upwork           Anywhere    \n",
       "4  Bank Street College of Education    United States      \n",
       "\n",
       "                                                 via  \\\n",
       "0                                       via linkedin   \n",
       "1                                       via linkedin   \n",
       "2                                         via indeed   \n",
       "3                                         via upwork   \n",
       "4  via higher education recruitment consortium (h...   \n",
       "\n",
       "                                         description  \\\n",
       "0  as the leader in cloud-managed it, cisco merak...   \n",
       "1  as a senior business analyst you will contribu...   \n",
       "2  overview:\\n\\namyx is seeking to hire a data an...   \n",
       "3  i am looking for someone to help me build an a...   \n",
       "4  position vacancy – data analyst to support the...   \n",
       "\n",
       "                                          extensions schedule_type  \\\n",
       "0  ['22 hours ago', 'Work from home', 'Full-time'...     Full-time   \n",
       "1  ['53 minutes ago', 'Work from home', 'Full-tim...     Full-time   \n",
       "2                       ['3 hours ago', 'Full-time']     Full-time   \n",
       "3   ['23 hours ago', 'Work from home', 'Contractor']    Contractor   \n",
       "4                      ['20 hours ago', 'Full-time']     Full-time   \n",
       "\n",
       "   work_from_home  ... python sql tableau bi tool power bi  aws  azure  excel  \\\n",
       "0            True  ...      0   1       1       1        0    1      0      0   \n",
       "1            True  ...      0   0       0       0        0    0      0      0   \n",
       "2            True  ...      0   1       0       0        0    1      1      1   \n",
       "3            True  ...      0   0       0       0        0    0      0      1   \n",
       "4            True  ...      0   0       0       0        0    0      0      1   \n",
       "\n",
       "   powerpoint  r  \n",
       "0           0  1  \n",
       "1           0  1  \n",
       "2           0  1  \n",
       "3           0  1  \n",
       "4           1  1  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading full_matcher ...\n",
      "loading abv_matcher ...\n",
      "loading full_uni_matcher ...\n",
      "loading low_form_matcher ...\n",
      "loading token_matcher ...\n"
     ]
    }
   ],
   "source": [
    "# NLP + skillner\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "# init skill extractor\n",
    "skill_extractor = SkillExtractor(nlp, SKILL_DB, PhraseMatcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #dictionnaires for each row\n",
    "# def skills(text):\n",
    "#     try:\n",
    "#         skills_ex = skill_extractor.annotate(text)\n",
    "#         return(skills_ex)\n",
    "#     except Exception as e:\n",
    "#         return None\n",
    "\n",
    "# # applies the function to the range of rows specified by indexing\n",
    "# df_main['skills_ex'] = df_main['description_cleaned'][0:5].apply(skills) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want a list of dictionnaires run the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workaround of skillners bugs by ignoring the errors\n",
    "# looping through rows in df.description_cleaned\n",
    "counter = 0\n",
    "#The list that returns the indexes of the error \"out of range\" for [0:500] = [146, 171, 247, 249, 274, 285, 286, 355, 357, 438, 499]\n",
    "index_list = [] \n",
    "skills_list = [] \n",
    "\n",
    "\n",
    "for id in df_main['description_cleaned'][29500:31000]: #specify the index range \n",
    "    try:\n",
    "        skills_ex = skill_extractor.annotate(id)\n",
    "        skills_list.append(skills_ex)\n",
    "        counter = counter + 1 #ignores this when fails\n",
    "        print(counter)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing entry at counter {counter}: {str(e)}\")\n",
    "        index_list.append(counter) # list of indexes that werent processed\n",
    "        counter = counter + 1\n",
    "        continue\n",
    "\n",
    "print(counter)\n",
    "print(len(skills_list))\n",
    "display(skills_list)\n",
    "print(index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_list_df = pd.DataFrame(skills_list)\n",
    "#skills_list_df.to_csv(\"data/skills_list_31500_32022.csv\") # index_list [18,19]\n",
    "#skills_list_df.to_csv(\"data/skills_list_31000_31500.csv\") # index list empty\n",
    "#skills_list_df.to_csv(\"data/skills_list_29500_31000.csv\") #[2, 98, 103, 261, 262, 282, 311, 448, 526, 758, 759, 883, 911, 926, 943, 955, 963, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SKILLS = pd.read_csv(\"data/skills_list_31500_32022.csv\")\n",
    "#SKILLS = pd.read_csv(\"data/skills_list_31000_31500.csv\")# genau angucken! position summary what you ii do working at ...\n",
    "SKILLS = pd.read_csv(\"data/skills_list_29500_31000.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skill</th>\n",
       "      <th>count</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analytics</td>\n",
       "      <td>3385</td>\n",
       "      <td>Hard Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Management</td>\n",
       "      <td>1949</td>\n",
       "      <td>Soft Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Communications</td>\n",
       "      <td>1899</td>\n",
       "      <td>Soft Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SQL (Programming Language)</td>\n",
       "      <td>1780</td>\n",
       "      <td>Hard Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tooling</td>\n",
       "      <td>1769</td>\n",
       "      <td>Hard Skill</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        skill  count        type\n",
       "0                   Analytics   3385  Hard Skill\n",
       "1                  Management   1949  Soft Skill\n",
       "2              Communications   1899  Soft Skill\n",
       "3  SQL (Programming Language)   1780  Hard Skill\n",
       "4                     Tooling   1769  Hard Skill"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tryme = pd.read_excel(\"data/skills_counts_jobs_20.xlsx\")\n",
    "tryme.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tokens = df_main.copy()\n",
    "df_tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#starting tokenization\n",
    "tryme[\"skill\"] = tryme[\"skill\"].str.lower().head(50) # for top 50 skills # data collection\n",
    "\n",
    "skills_list = tryme[\"skill\"].head(50)\n",
    "\n",
    "# create new columns for each skill\n",
    "for skill in skills_list:\n",
    "    df_tokens[skill] = df_tokens['description_cleaned'].apply(lambda x: 1 if skill.lower() in x.lower() else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skill</th>\n",
       "      <th>count</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>communications</td>\n",
       "      <td>3385</td>\n",
       "      <td>Hard Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sql (programming language)</td>\n",
       "      <td>1949</td>\n",
       "      <td>Soft Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positivity</td>\n",
       "      <td>1899</td>\n",
       "      <td>Soft Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>maintainability</td>\n",
       "      <td>1780</td>\n",
       "      <td>Hard Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>operations</td>\n",
       "      <td>1769</td>\n",
       "      <td>Hard Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>collaboration</td>\n",
       "      <td>1621</td>\n",
       "      <td>Soft Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>disabilities</td>\n",
       "      <td>1448</td>\n",
       "      <td>Hard Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>research</td>\n",
       "      <td>1385</td>\n",
       "      <td>Soft Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>data quality</td>\n",
       "      <td>1191</td>\n",
       "      <td>Soft Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>levelling</td>\n",
       "      <td>1131</td>\n",
       "      <td>Hard Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>equalization</td>\n",
       "      <td>1090</td>\n",
       "      <td>Soft Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>presentations</td>\n",
       "      <td>1054</td>\n",
       "      <td>Hard Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>statistics</td>\n",
       "      <td>1029</td>\n",
       "      <td>Hard Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>industrialization</td>\n",
       "      <td>998</td>\n",
       "      <td>Hard Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>dashboard</td>\n",
       "      <td>976</td>\n",
       "      <td>Soft Skill</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         skill  count        type\n",
       "0               communications   3385  Hard Skill\n",
       "1   sql (programming language)   1949  Soft Skill\n",
       "2                   positivity   1899  Soft Skill\n",
       "3              maintainability   1780  Hard Skill\n",
       "4                   operations   1769  Hard Skill\n",
       "5                collaboration   1621  Soft Skill\n",
       "6                 disabilities   1448  Hard Skill\n",
       "7                     research   1385  Soft Skill\n",
       "8                 data quality   1191  Soft Skill\n",
       "9                    levelling   1131  Hard Skill\n",
       "10                equalization   1090  Soft Skill\n",
       "11               presentations   1054  Hard Skill\n",
       "12                  statistics   1029  Hard Skill\n",
       "13           industrialization    998  Hard Skill\n",
       "14                   dashboard    976  Soft Skill"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tryme[\"skill\"] = tryme[\"skill\"].drop(2).reset_index(drop=True)\n",
    "tryme.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "management                    18399\n",
       "analytics                     16913\n",
       "communications                 2624\n",
       "tooling                         287\n",
       "sql (programming language)        4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens[[\"analytics\", \"management\", \"communications\", \"sql (programming language)\", \"tooling\"]].sum(axis=0).sort_values(ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['leveling'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m display(\u001b[43mdf_tokens\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mleveling\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdescription_cleaned\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/nf_base_capstone/lib/python3.9/site-packages/pandas/core/frame.py:3902\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3901\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3902\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3904\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/nf_base_capstone/lib/python3.9/site-packages/pandas/core/indexes/base.py:6114\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6111\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6112\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6114\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6116\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6118\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/nf_base_capstone/lib/python3.9/site-packages/pandas/core/indexes/base.py:6178\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6177\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6178\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['leveling'] not in index\""
     ]
    }
   ],
   "source": [
    "display(df_tokens[[\"leveling\", \"description_cleaned\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "position vacancy – data analyst to support the ed center’s project portfolio, bank street education center (the ed center)summary position: bank street education center (the ed center), a division within bank street college of education (the college) created to support the college’s systems-level work with school districts, is currently seeking a data analyst to support projects across the ed... center’s portfolio. they will lead measurement planning as well as develop associated data collection tools to support their assigned projects.key relationships: the data analyst will report to the director of impact and work closely with project teams as well as the broader sspp team.responsibilities: in collaboration with their supervisors, their project teams, and broader sspp team, the data analyst will be responsible for the following:analytics:• collaborating with relevant team members to draft a measurement plan that clearly documents desired outcomes and goals as well as associated project metrics.• in collaboration with key stakeholders, creating data collection tools that capture data aligned to key project metrics as defined by project leads and in the measurement plan (e.g., tools to support teachers to measure the impact of inquiry cycles, surveys, observation tools, interviews).• analyzing key data points and prepare reports to share with internal and external audiences (e.g., team meetings, district teams, funder reporting and proposals, marketing materials, etc.).• collecting and tracking data around the quality of experiences of participants, and reflecting on this information to debrief learnings and surface implications on the project with project leaders.• building project tools (e.g., feedback forms, surveys, session reports, final report, etc.) and vetting internally.• troubleshooting technological support as it relates to data collection tools, as needed.• creating data visualizations for use by various stakeholders (teachers visualizing student-level data, principals visualizing school-level data, districts visualizing district-level data, and ed center team visualizing the progress and impact of our network).• supporting in building and maintaining data management structures and tools for short-term and long-term qualitative and quantitative data collection and analysis.• supporting project teams to deeply understand the district context by researching the history of the city/district and staying current on local topics.• engaging in self-initiated and job-provided professional development activities to stay current on matters related to education, data analysis, and project-related content.• meeting with the project team, sspp team, and ed center team leaders over the lifespan of the project to “step back” and check in on the progress of and make adjustments to the data collection of the project.• contributing to the sspp-wide analytics by informing a broader analytics strategy across the portfolio and serving as an analyst on other project teams as assigned; and performing related duties as assigned.project management & operations:• managing timelines for various analytics responsibilities and collaborating with the project manager to move forward respective workstreams.• attending professional learning engagements to support in data collection and implementation.• providing technical support for professional learning engagements, including managing logistical details and platform guidance in preparation of and during sessions.• supporting in maintaining a functional and supportive organizational system within the g:drive, files, documented systems and processes, etc.• performing related duties as assigned.qualifications:skills & knowledge:• background in research and education, with prior experience on research projects analyzing student-level data• expertise in interpreting and summarizing academic research as well as the ability to present information in multiple formats for diverse audiences.• strong problem solving skills with the ability to perform independently.• strong communications skills (email, writing, in-person).experiences:• at least 3-5 years of work experience• master’s degree in education, nonprofit policy, analytics, or related field• experience working with diverse and/or historically deprioritized student populations at the classroom- and/or school- levels.• experience with reporting and/or managing grant-funded projects and associated deliverables• ability to work effectively with data of varying levels of quality and validity; attention to detail and ability to identify issues and inconsistencies in data.• ability to manage complex and multiple projects• demonstrated ability to work collaboratively with demonstrated google suite, powerpoint, excel, google data studio, project management, and analytical skills diverse range of team members and external partners.• demonstrated ability to think strategically & execute on ideasmindsets:• an intersectional, anti-racist lens and strengths-based approach to data management, and team collaboration• a reflective learner’s stance• enthusiasm for learning and a willingness to self-initiate professional learning opportunities• strong work ethic and willingness to take initiativesalary range: $70,000 - $85,000additional information:• this position is contingent upon available funding.• please apply online by submitting a cover letter and resume for the position in the “job opportunities” section under the “about” tab on bank street’s website:https://www.bankstreet.edu/administrative-offices/human-resources/job-opportunities/• please address cover letters to:tracy fray-oliversenior associate vice president, bank street education centerbank street college610 west 112th streetnew york, ny 10025• please include where you came across this job posting in your cover letter.bank street college of education is an equal opportunity employer and does not discriminateon the basis of race, sexual orientation ethnic origin, sex, or disability in its employmentpolicies and other college administered programs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skill list of jobs_20 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data from sql to python\n",
    "import sql_functions as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skill</th>\n",
       "      <th>count</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analytics</td>\n",
       "      <td>3385</td>\n",
       "      <td>Hard Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Management</td>\n",
       "      <td>1949</td>\n",
       "      <td>Soft Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Communications</td>\n",
       "      <td>1899</td>\n",
       "      <td>Soft Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SQL (Programming Language)</td>\n",
       "      <td>1780</td>\n",
       "      <td>Hard Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tooling</td>\n",
       "      <td>1769</td>\n",
       "      <td>Hard Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5618</th>\n",
       "      <td>Deconstruction</td>\n",
       "      <td>1</td>\n",
       "      <td>Hard Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5619</th>\n",
       "      <td>Motorcycles</td>\n",
       "      <td>1</td>\n",
       "      <td>Hard Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5620</th>\n",
       "      <td>Holistic Health</td>\n",
       "      <td>1</td>\n",
       "      <td>Hard Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5621</th>\n",
       "      <td>Body Work</td>\n",
       "      <td>1</td>\n",
       "      <td>Hard Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5622</th>\n",
       "      <td>Workplace Wellness</td>\n",
       "      <td>1</td>\n",
       "      <td>Hard Skill</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5623 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           skill  count        type\n",
       "0                      Analytics   3385  Hard Skill\n",
       "1                     Management   1949  Soft Skill\n",
       "2                 Communications   1899  Soft Skill\n",
       "3     SQL (Programming Language)   1780  Hard Skill\n",
       "4                        Tooling   1769  Hard Skill\n",
       "...                          ...    ...         ...\n",
       "5618              Deconstruction      1  Hard Skill\n",
       "5619                 Motorcycles      1  Hard Skill\n",
       "5620             Holistic Health      1  Hard Skill\n",
       "5621                   Body Work      1  Hard Skill\n",
       "5622          Workplace Wellness      1  Hard Skill\n",
       "\n",
       "[5623 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load jobs data\n",
    "\n",
    "schema = 'capstone_datacvpro'\n",
    "\n",
    "# jobs_20 = sf.get_dataframe(f' SELECT * FROM {schema}.analysts_20')\n",
    "# display(jobs_20)\n",
    "\n",
    "df_skills = sf.get_dataframe(f' SELECT * FROM {schema}.skills_20') # skill table\n",
    "display(df_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5605    1\n",
       "5606    1\n",
       "5607    1\n",
       "5608    1\n",
       "5609    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#df_skills= df_skills.drop(92).reset_index(drop=True)\n",
    "# dropped skills: analytics, management, tooling, operations, disabilities, levelling,  equalization, activism, industrialization, job descriptions\t, additives (34), governance, Hostile Work Environment, \n",
    "display(df_skills[\"count\"].tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skill</th>\n",
       "      <th>count</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Communications</td>\n",
       "      <td>1899</td>\n",
       "      <td>Soft Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SQL (Programming Language)</td>\n",
       "      <td>1780</td>\n",
       "      <td>Hard Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positivity</td>\n",
       "      <td>1621</td>\n",
       "      <td>Soft Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Maintainability</td>\n",
       "      <td>1448</td>\n",
       "      <td>Hard Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Collaboration</td>\n",
       "      <td>1191</td>\n",
       "      <td>Soft Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>Database Queries</td>\n",
       "      <td>41</td>\n",
       "      <td>Hard Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>Good Documentation Practices</td>\n",
       "      <td>41</td>\n",
       "      <td>Hard Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>Very Large Databases (VLDB)</td>\n",
       "      <td>41</td>\n",
       "      <td>Hard Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>Diagramming Software</td>\n",
       "      <td>41</td>\n",
       "      <td>Hard Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>Sales Operations</td>\n",
       "      <td>41</td>\n",
       "      <td>Hard Skill</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>511 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            skill  count        type\n",
       "0                  Communications   1899  Soft Skill\n",
       "1      SQL (Programming Language)   1780  Hard Skill\n",
       "2                      Positivity   1621  Soft Skill\n",
       "3                 Maintainability   1448  Hard Skill\n",
       "4                   Collaboration   1191  Soft Skill\n",
       "..                            ...    ...         ...\n",
       "507              Database Queries     41  Hard Skill\n",
       "508  Good Documentation Practices     41  Hard Skill\n",
       "509   Very Large Databases (VLDB)     41  Hard Skill\n",
       "510          Diagramming Software     41  Hard Skill\n",
       "511              Sales Operations     41  Hard Skill\n",
       "\n",
       "[511 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_top_skills = df_skills.query(\"count > 40\").copy()\n",
    "display(df_top_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_top_skills\n",
    "# Stemming: reduce words to their root\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Search for word stem\n",
    "2. Search for entity r, e\n",
    "3. Remove () and insides, e.g., sql instead of sql (programming language)\n",
    "4. key performance indicator or kpi?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Communications  :  commun\n",
      "SQL (Programming Language)  :  sql (programming language)\n",
      "Positivity  :  posit\n",
      "Maintainability  :  maintain\n",
      "Collaboration  :  collabor\n",
      "Research  :  research\n",
      "Data Quality  :  data qu\n",
      "Presentations  :  present\n",
      "Statistics  :  statist\n",
      "Dashboard  :  dashboard\n",
      "Planning  :  plan\n",
      "Tableau (Business Intelligence Software)  :  tableau (business intelligence software)\n",
      "Python (Programming Language)  :  python (programming language)\n",
      "Component Object Model (COM)  :  component object model (com)\n",
      "Integration  :  integr\n",
      "Computer Science  :  computer sci\n",
      "E (Programming Language)  :  e (programming language)\n",
      "Decisiveness  :  decis\n",
      "Innovation  :  innov\n",
      "Writing  :  write\n",
      "Personalization  :  person\n",
      "Source Data  :  source data\n",
      "Verbal Communication Skills  :  verbal communication skil\n",
      "Consulting  :  consult\n",
      "Data Visualization  :  data visu\n",
      "Professionalism  :  profession\n",
      "Data Analysis  :  data analysi\n",
      "Accessioning  :  access\n",
      "Minimum Data Set  :  minimum data set\n",
      "Coloring  :  color\n",
      "Executable  :  execut\n",
      "Exploratory Data Analysis  :  exploratory data analysi\n",
      "Problem Solving  :  problem solv\n",
      "Automation  :  autom\n",
      "Data Management  :  data manag\n",
      "Data Mapper Patterns  :  data mapper pattern\n",
      "Data Governance  :  data govern\n",
      "R (Programming Language)  :  r (programming language)\n",
      "Extract Transform Load (ETL)  :  extract transform load (etl)\n",
      "Coordinating  :  coordin\n",
      "Finance  :  financ\n",
      "Business Intelligence  :  business intellig\n",
      "Visualization  :  visual\n",
      "Receivables  :  receiv\n",
      "Ad Hoc Testing  :  ad hoc test\n",
      "Medic  :  medic\n",
      "Accounting  :  account\n",
      "Sourcing  :  sourc\n",
      "Collections  :  collect\n",
      "SAS (Software)  :  sas (software)\n",
      "Sales  :  sale\n",
      "Hyperion Data Management  :  hyperion data manag\n",
      "Prioritization  :  priorit\n",
      "Project Management  :  project manag\n",
      "Data Science  :  data sci\n",
      "Dataset  :  dataset\n",
      "Translations  :  translat\n",
      "Limiter  :  limit\n",
      "Data Modeling  :  data model\n",
      "Scheduling  :  schedul\n",
      "Analytical Skills  :  analytical skil\n",
      "Leadership  :  leadership\n",
      "Data Processing Systems  :  data processing system\n",
      "Resourcing  :  resourc\n",
      "Clinical Data Warehouse  :  clinical data warehous\n",
      "Library For WWW In Perl  :  library for www in perl\n",
      "Business Requirements  :  business requir\n",
      "Programming (Music)  :  programming (music)\n",
      "Centering  :  center\n",
      "Decision Making  :  decision mak\n",
      "Track (Rail Transport)  :  track (rail transport)\n",
      "Physics  :  physic\n",
      "Validations  :  valid\n",
      "Java Data Mining  :  java data min\n",
      "Interactivity  :  interact\n",
      "Information Systems  :  information system\n",
      "Consumables  :  consum\n",
      "Banking  :  bank\n",
      "SAS Statistical Analysis  :  sas statistical analysi\n",
      "Written Communication  :  written commun\n",
      "Investigation  :  investig\n",
      "Creativity  :  creativ\n",
      "Business Process  :  business process\n",
      "Process Improvements  :  process improv\n",
      "Logical Data Models  :  logical data model\n",
      "Good Agricultural Practices  :  good agricultural practic\n",
      "Power BI  :  power bi\n",
      "Digitization  :  digit\n",
      "Relational Databases  :  relational databas\n",
      "Big Data  :  big data\n",
      "Microsoft SQL Servers  :  microsoft sql serv\n",
      "Storage Area Network (SAN)  :  storage area network (san)\n",
      "Claims Processing  :  claims process\n",
      "Survey Data Collection  :  survey data collect\n",
      "Information Technology  :  information technolog\n",
      "Controllability  :  control\n",
      "Proactivity  :  proactiv\n",
      "Forecasting  :  forecast\n",
      "Branding  :  brand\n",
      "Health Care Industry  :  health care industri\n",
      "Scale (Map)  :  scale (map)\n",
      "Strategic Business Unit  :  strategic business unit\n",
      "Investments  :  invest\n",
      "Microsoft Office  :  microsoft offic\n",
      "Data Collection  :  data collect\n",
      "Financial Services  :  financial servic\n",
      "TARGET 3001!  :  target 3001!\n",
      "Tracking (Commercial Airline Flight)  :  tracking (commercial airline flight)\n",
      "Data Engineering  :  data engin\n",
      "Detail Oriented  :  detail ori\n",
      "Patentable Subject Matter  :  patentable subject matt\n",
      "Metadata  :  metadata\n",
      "Genetics  :  genet\n",
      "Auditing  :  audit\n",
      "Workflows  :  workflow\n",
      "B (Programming Language)  :  b (programming language)\n",
      "Supervision  :  supervis\n",
      "Scripting  :  script\n",
      "Business Partnering  :  business partn\n",
      "Source (Game Engine)  :  source (game engine)\n",
      "Long-Term Care  :  long-term car\n",
      "Mapping  :  map\n",
      "Data Extraction  :  data extract\n",
      "Data Integrity  :  data integr\n",
      "Scholastic READ 180  :  scholastic read 180\n",
      "Self Starter  :  self start\n",
      "Agility  :  agil\n",
      "Hospitality  :  hospit\n",
      "Time Management  :  time manag\n",
      "Reporting Tools  :  reporting tool\n",
      "System Programming Language  :  system programming languag\n",
      "Software Development  :  software develop\n",
      "Product Data Management  :  product data manag\n",
      "Key Performance Indicators (KPIs)  :  key performance indicators (kpis)\n",
      "Instructing  :  instruct\n",
      "Adaptability  :  adapt\n",
      "SPSS (Statistical Software)  :  spss (statistical software)\n",
      "Customer Service  :  customer servic\n",
      "Troubleshooting (Problem Solving)  :  troubleshooting (problem solving)\n",
      "Reliability  :  reliabl\n",
      "Infrastructure  :  infrastructur\n",
      "Microsoft Excel  :  microsoft excel\n",
      "Root Cause Analysis  :  root cause analysi\n",
      "Acceptance and Commitment Therapy (ACT)  :  acceptance and commitment therapy (act)\n",
      "Accountability  :  account\n",
      "Self-Motivation  :  self-motiv\n",
      "Supply Chain  :  supply chain\n",
      "Machine Learning Methods  :  machine learning method\n",
      "Prediction  :  predict\n",
      "Market Data  :  market data\n",
      "Data Warehouse Systems  :  data warehouse system\n",
      "Algorithms  :  algorithm\n",
      "Organizational Skills  :  organizational skil\n",
      "Customer Data Integration  :  customer data integr\n",
      "Business Objects Framework  :  business objects framework\n",
      "M (Programming Language)  :  m (programming language)\n",
      "Quality Assurance  :  quality assur\n",
      "Cross-Functional Coordination  :  cross-functional coordin\n",
      "Database Design  :  database design\n",
      "Registration Evaluation Authorisation And Restriction Of Chemicals (REACH) Regulations  :  registration evaluation authorisation and restriction of chemicals (reach) regul\n",
      "Machine Learning  :  machine learn\n",
      "Self Service Technologies  :  self service technolog\n",
      "High-Level Architecture  :  high-level architectur\n",
      "Web SQL Databases  :  web sql databas\n",
      "Cross-Functional Team Leadership  :  cross-functional team leadership\n",
      "Dissemination  :  dissemin\n",
      "Data Entry  :  data entri\n",
      "Predictive Modeling  :  predictive model\n",
      "Management Systems  :  management system\n",
      "AD Model Builder (ADMB)  :  ad model builder (admb)\n",
      "Economics  :  econom\n",
      "Compilers  :  compil\n",
      "Quality Control  :  quality control\n",
      "Critical Thinking  :  critical think\n",
      "Business Analysis  :  business analysi\n",
      "JavaScript (Programming Language)  :  javascript (programming language)\n",
      "Complex Problem Solving  :  complex problem solv\n",
      "Business Analytics  :  business analyt\n",
      "Mathematical Statistics  :  mathematical statist\n",
      "Commercialization  :  commerci\n",
      "Data Manipulation  :  data manipul\n",
      "Customer Relationship Management (CRM) Software  :  customer relationship management (crm) softwar\n",
      "Scalability  :  scalabl\n",
      "Licensing  :  licens\n",
      "Informatica Cloud  :  informatica cloud\n",
      "Concision  :  concis\n",
      "Naturalization  :  natur\n",
      "Public Health  :  public health\n",
      "Customer Experience  :  customer experi\n",
      "Budgeting  :  budget\n",
      "Stored Procedure  :  stored procedur\n",
      "Timelines  :  timelin\n",
      "Data Transformation  :  data transform\n",
      "Creative Problem-Solving  :  creative problem-solv\n",
      "Pipelining  :  pipelin\n",
      "C (Programming Language)  :  c (programming language)\n",
      "Calculations  :  calcul\n",
      "Financial Data  :  financial data\n",
      "Extensible Markup Language (XML)  :  extensible markup language (xml)\n",
      "Data Validation  :  data valid\n",
      "Statistical Packages  :  statistical packag\n",
      "Secondary Source Maps  :  secondary source map\n",
      "Statistical Modeling  :  statistical model\n",
      "Data Mapping  :  data map\n",
      "Spreadsheets  :  spreadsheet\n",
      "Data Profiling  :  data profil\n",
      "Data Presentation  :  data present\n",
      "Data Structures  :  data structur\n",
      "Business Intelligence Tools  :  business intelligence tool\n",
      "Java (Programming Language)  :  java (programming language)\n",
      "Sustainability  :  sustain\n",
      "Data Integration  :  data integr\n",
      "English Language  :  english languag\n",
      "MySQL  :  mysql\n",
      "Mobility  :  mobil\n",
      "Apache Hive  :  apache h\n",
      "PL/SQL  :  pl/sql\n",
      "Socialization  :  social\n",
      "SQL Server Integration Services (SSIS)  :  sql server integration services (ssis)\n",
      "Business Support Systems  :  business support system\n",
      "Data Processing  :  data process\n",
      "JIRA Studio  :  jira studio\n",
      "Finalization  :  final\n",
      "Economic Statistics  :  economic statist\n",
      "Drawing  :  draw\n",
      "Data Warehousing  :  data wareh\n",
      "Quality Improvement  :  quality improv\n",
      "Derivatives  :  deriv\n",
      "LO-NOx Burner  :  lo-nox burn\n",
      "Transformation (Genetics)  :  transformation (genetics)\n",
      "Capitalization  :  capit\n",
      "Development Testing  :  development test\n",
      "Professional Project Manager  :  professional project manag\n",
      "Aggregator  :  aggreg\n",
      "Health Data Specialists  :  health data specialist\n",
      "Business Systems  :  business system\n",
      "Google Analytics  :  google analyt\n",
      "Reconciliation  :  reconcili\n",
      "Logistics  :  logist\n",
      "Epidemiology  :  epidemiolog\n",
      "Nice (Unix Utility)  :  nice (unix utility)\n",
      "Articulation  :  articul\n",
      "New Product Development  :  new product develop\n",
      "Risk Management  :  risk manag\n",
      "Information Management  :  information manag\n",
      "Authorization (Computing)  :  authorization (computing)\n",
      "FourGen Computer-Aided Software Engineering (CASE) Tools  :  fourgen computer-aided software engineering (case) tool\n",
      "Friendliness  :  friendli\n",
      "Alternators  :  altern\n",
      "Report Generators  :  report gener\n",
      "Adoptions  :  adopt\n",
      "Life Insurance Sales  :  life insurance sal\n",
      "Technical Solution Design  :  technical solution design\n",
      "Quantitative Analysis  :  quantitative analysi\n",
      "Sage SAFE X3  :  sage safe x3\n",
      "Onboarding  :  onboard\n",
      "Business Operations  :  business oper\n",
      "Equities  :  equiti\n",
      "Program Management  :  program manag\n",
      "Loans  :  loan\n",
      "Purchasing  :  purchas\n",
      "Cancer  :  cancer\n",
      "Acting  :  act\n",
      "Professional Development Programs  :  professional development program\n",
      "Data Architecture  :  data architectur\n",
      "Graphing  :  graph\n",
      "Integrated Product Team  :  integrated product team\n",
      "Team Performance Management  :  team performance manag\n",
      "Macros  :  macro\n",
      "Technology Solutions  :  technology solut\n",
      "Billing  :  bill\n",
      "Statistical Software  :  statistical softwar\n",
      "Numbers (Spreadsheet)  :  numbers (spreadsheet)\n",
      "Language Experience Approach  :  language experience approach\n",
      "Database Models  :  database model\n",
      "Real Time Java  :  real time java\n",
      "Real Estate  :  real est\n",
      "Unstructured Data  :  unstructured data\n",
      "Engineering Management  :  engineering manag\n",
      "Continuous Improvement Process  :  continuous improvement process\n",
      "Electronics  :  electron\n",
      "Surveys  :  survey\n",
      "Data Steward  :  data steward\n",
      "Electronic Data Capture (EDC)  :  electronic data capture (edc)\n",
      "Data Element  :  data el\n",
      "Informatics  :  informat\n",
      "Management Process  :  management process\n",
      "Survey Data Analysis  :  survey data analysi\n",
      "Functional Requirement  :  functional requir\n",
      "Health Systems  :  health system\n",
      "Use Case Diagram  :  use case diagram\n",
      "Alteryx  :  alteryx\n",
      "Ordinances  :  ordin\n",
      "Streamlines  :  streamlin\n",
      "Amazon Redshift  :  amazon redshift\n",
      "Staging  :  stage\n",
      "Team Oriented  :  team ori\n",
      "MFG/Pro (ERP)  :  mfg/pro (erp)\n",
      "Multiple-System Operator  :  multiple-system oper\n",
      "Data Management Platforms  :  data management platform\n",
      "Profile Scripting Language  :  profile scripting languag\n",
      "Business Development  :  business develop\n",
      "Procurement  :  procur\n",
      "Amazon Data Pipeline  :  amazon data pipelin\n",
      "Cleaned Data  :  cleaned data\n",
      "ArcGIS (GIS Software)  :  arcgis (gis software)\n",
      "Application Development  :  application develop\n",
      "Configuration Management Databases  :  configuration management databas\n",
      "Data Security  :  data secur\n",
      "Perspective (Graphical)  :  perspective (graphical)\n",
      "Process Automation Systems  :  process automation system\n",
      "Federal Laws  :  federal law\n",
      "Performance Metric  :  performance metr\n",
      "Service Provider  :  service provid\n",
      "Advertisement  :  advertis\n",
      "Production Management  :  production manag\n",
      "Life Cycle Assessment  :  life cycle assess\n",
      "Operational Data Store  :  operational data stor\n",
      "Physician Data Query  :  physician data queri\n",
      "Technical Support  :  technical support\n",
      "Transparency (Human-Computer Interaction)  :  transparency (human-computer interaction)\n",
      "Editing  :  edit\n",
      "Mobile Application Software  :  mobile application softwar\n",
      "Consolidation  :  consolid\n",
      "Business Administration  :  business administr\n",
      "Test Planning  :  test plan\n",
      "Curiosity  :  curios\n",
      "Diversity And Inclusion  :  diversity and inclus\n",
      "Pharmaceuticals  :  pharmaceut\n",
      "Medical Insurance Claims  :  medical insurance claim\n",
      "Post-Hoc Analysis  :  post-hoc analysi\n",
      "Quantitative Data Analysis  :  quantitative data analysi\n",
      "Patient Care Technician  :  patient care technician\n",
      "Direct-to-Consumer (DTC)  :  direct-to-consumer (dtc)\n",
      "Advising  :  advis\n",
      "Business Strategies  :  business strategi\n",
      "Biology  :  biolog\n",
      "Data Encryption Standard  :  data encryption standard\n",
      "Small Business Accounting  :  small business account\n",
      "Raw Data  :  raw data\n",
      "Customer Support Analyst  :  customer support analyst\n",
      "Strategic Planning  :  strategic plan\n",
      "Financial Business Solution  :  financial business solut\n",
      "Reflectivity  :  reflect\n",
      "Data Centers  :  data cent\n",
      "Data Conversion  :  data convers\n",
      "Systems Analysis  :  systems analysi\n",
      "Operations Support Systems  :  operations support system\n",
      "Computer Engineering  :  computer engin\n",
      "Inquiry  :  inquiri\n",
      "E-Tools  :  e-tool\n",
      "Data Files  :  data fil\n",
      "System Requirements  :  system requir\n",
      "Pathing  :  path\n",
      "Operations Research  :  operations research\n",
      "Change Management  :  change manag\n",
      "IText (Free PDF Software)  :  itext (free pdf software)\n",
      "Lean Product Development  :  lean product develop\n",
      "Production Support  :  production support\n",
      "User Experience  :  user experi\n",
      "Commissioning  :  commiss\n",
      "Snowflake (Data Warehouse)  :  snowflake (data warehouse)\n",
      "Health Care Benefits  :  health care benefit\n",
      "Configuration Management  :  configuration manag\n",
      "Managed Care  :  managed car\n",
      "Data Pipeline  :  data pipelin\n",
      "Document Process Automation  :  document process autom\n",
      "Business Performance Management  :  business performance manag\n",
      "Data Flow Diagram  :  data flow diagram\n",
      "Stewardship  :  stewardship\n",
      "Statistical Methods  :  statistical method\n",
      "Cooperation  :  cooper\n",
      "Software Engineering  :  software engin\n",
      "Business Acumen  :  business acumen\n",
      "Library  :  librari\n",
      "Foods  :  food\n",
      "Eyes  :  eye\n",
      "Process Development  :  process develop\n",
      "Master Data Management  :  master data manag\n",
      "Teamwork  :  teamwork\n",
      "Refining  :  refin\n",
      "Capital Markets  :  capital market\n",
      "Service Data Objects  :  service data object\n",
      "Experience Design  :  experience design\n",
      "Query Languages  :  query languag\n",
      "Operating Systems  :  operating system\n",
      "Retirement Planning  :  retirement plan\n",
      "Peoplesoft Human Resources  :  peoplesoft human resourc\n",
      "Teaching  :  teach\n",
      "Requisition  :  requisit\n",
      "Real Time Data  :  real time data\n",
      "Data Dictionary  :  data dictionari\n",
      "Performance Analysis  :  performance analysi\n",
      "Demonstration Skills  :  demonstration skil\n",
      "Asset Management  :  asset manag\n",
      "Market Requirements Documents  :  market requirements docu\n",
      "Storages  :  storag\n",
      "Humanism  :  human\n",
      "Benchmarking  :  benchmark\n",
      "Database Development  :  database develop\n",
      "Report Designer  :  report design\n",
      "Clinical Research  :  clinical research\n",
      "Mathematical Economics  :  mathematical econom\n",
      "Microsoft Access  :  microsoft access\n",
      "New Business Development  :  new business develop\n",
      "Linux  :  linux\n",
      "Deep Diving  :  deep div\n",
      "Human Development Report  :  human development report\n",
      "Installation  :  instal\n",
      "User Requirements Documents  :  user requirements docu\n",
      "Project Planning  :  project plan\n",
      "Negotiation  :  negoti\n",
      "Predictive Analytics  :  predictive analyt\n",
      "Reproductive Health Care  :  reproductive health car\n",
      "Iterators  :  iter\n",
      "IBM System Z10 (IBM System/360 Mainframe Line)  :  ibm system z10 (ibm system/360 mainframe line)\n",
      "Oracle SQL Developer  :  oracle sql develop\n",
      "Test Data  :  test data\n",
      "Team Leadership  :  team leadership\n",
      "Enterprise Report Management (ERM)  :  enterprise report management (erm)\n",
      "Workday (Software)  :  workday (software)\n",
      "Surfacing  :  surfac\n",
      "Information Security Management  :  information security manag\n",
      "Security Clearance  :  security clear\n",
      "Intellectual Curiosity  :  intellectual curios\n",
      "Product Marketing  :  product market\n",
      "Industry Standard Architecture  :  industry standard architectur\n",
      "Construction  :  construct\n",
      "Financial Institution  :  financial institut\n",
      "Digital Marketing  :  digital market\n",
      "Hyperion Financial Reporting  :  hyperion financial report\n",
      "Performance Reporting  :  performance report\n",
      "Test Case  :  test cas\n",
      "Database Systems  :  database system\n",
      "Service Industries  :  service industri\n",
      "Templates  :  templat\n",
      "Zope (CMS)  :  zope (cms)\n",
      "Self-Directed Learning  :  self-directed learn\n",
      "Business Process Management  :  business process manag\n",
      "Requirements Analysis  :  requirements analysi\n",
      "Project-Based Solutions  :  project-based solut\n",
      "Population Health  :  population health\n",
      "MicroStrategy  :  microstrategi\n",
      "Fixed Income  :  fixed incom\n",
      "Relationship Building  :  relationship build\n",
      "Agile Software Development  :  agile software develop\n",
      "Building Design  :  building design\n",
      "Social Sciences  :  social sci\n",
      "Virtualization  :  virtual\n",
      "Analytical Techniques  :  analytical techniqu\n",
      "Financial Analysis  :  financial analysi\n",
      "Environmentalism  :  environment\n",
      "Software Development Methodologies  :  software development methodolog\n",
      "Data System  :  data system\n",
      "Life Sciences  :  life sci\n",
      "Quality Management  :  quality manag\n",
      "Pandas (Python Package)  :  pandas (python package)\n",
      "Amazon Marketplace  :  amazon marketplac\n",
      "Unix  :  unix\n",
      "Bioinformatics  :  bioinformat\n",
      "Atlassian Confluence  :  atlassian conflu\n",
      "Design Verification Test  :  design verification test\n",
      "Securities (Finance)  :  securities (finance)\n",
      "Biostatistics  :  biostatist\n",
      "Conceptualization  :  conceptu\n",
      "Instrumentation  :  instrument\n",
      "Estimators  :  estim\n",
      "Experimentation  :  experiment\n",
      "Reference Data  :  reference data\n",
      "Entry Sequenced Data Set  :  entry sequenced data set\n",
      "Functional Specification  :  functional specif\n",
      "Interpersonal Communications  :  interpersonal commun\n",
      "Secret Clearance  :  secret clear\n",
      "Data Migration  :  data migr\n",
      "Data Cleansing  :  data cleans\n",
      "Data Compilation  :  data compil\n",
      "Financial Modeling  :  financial model\n",
      "Outliner  :  outlin\n",
      "Engineering Statistics  :  engineering statist\n",
      "Product Management  :  product manag\n",
      "Performance Tuning  :  performance tun\n",
      "E-Commerce  :  e-commerc\n",
      "External Data Representation  :  external data represent\n",
      "Small Business Technologies  :  small business technolog\n",
      "Database Storage Structures  :  database storage structur\n",
      "Git (Version Control System)  :  git (version control system)\n",
      "Corrective Action Training  :  corrective action train\n",
      "Reservations  :  reserv\n",
      "Data Explorers  :  data explor\n",
      "Decision Support Systems  :  decision support system\n",
      "Performance Improvement  :  performance improv\n",
      "QlikView (Data Analytics Software)  :  qlikview (data analytics software)\n",
      "Digital Transformation  :  digital transform\n",
      "Professional Services  :  professional servic\n",
      "Indexer  :  index\n",
      "Offshoring  :  offshor\n",
      "Debugging  :  debug\n",
      "Investment Banking  :  investment bank\n",
      "Acceptance Testing  :  acceptance test\n",
      "Law Enforcement  :  law enforc\n",
      "Multitasking  :  multitask\n",
      "Data Mining  :  data min\n",
      "Transferable Skills Analysis  :  transferable skills analysi\n",
      "Cultivator  :  cultiv\n",
      "Business Model  :  business model\n",
      "Master Of Business Administration (MBA)  :  master of business administration (mba)\n",
      "Database Queries  :  database queri\n",
      "Good Documentation Practices  :  good documentation practic\n",
      "Very Large Databases (VLDB)  :  very large databases (vldb)\n",
      "Diagramming Software  :  diagramming softwar\n",
      "Sales Operations  :  sales oper\n"
     ]
    }
   ],
   "source": [
    "#make a list of all skills\n",
    "skill_list_top = df_top_skills.skill.tolist()\n",
    "\n",
    "# #stammer\n",
    "ps = PorterStemmer()\n",
    "  \n",
    "for w in skill_list_top:\n",
    "    print(w, \" : \", ps.stem(w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#starting tokenization\n",
    "df_skills[\"skill\"] = df_skills[\"skill\"].str.lower().head(50) # for top 50 skills # data collection\n",
    "\n",
    "skills_list = df_skills[\"skill\"].head(50)\n",
    "\n",
    "# create new columns for each skill\n",
    "for skill in skills_list:\n",
    "    df_tokens[skill] = df_tokens['description_cleaned'].apply(lambda x: 1 if skill.lower() in x.lower() else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2    False\n",
       "3    False\n",
       "4    False\n",
       "Name: levelling, dtype: bool"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'levelling'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mdf_tokens\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlevelling\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/nf_base_capstone/lib/python3.9/site-packages/pandas/core/series.py:1040\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1040\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/nf_base_capstone/lib/python3.9/site-packages/pandas/core/series.py:1156\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1156\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/nf_base_capstone/lib/python3.9/site-packages/pandas/core/indexes/range.py:418\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'levelling'"
     ]
    }
   ],
   "source": [
    "df_tokens = df_tokens[\"levelling\"] == True\n",
    "#display(df_tokens[[\"levelling\", \"description_cleaned\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'df_skills' is not defined\n"
     ]
    }
   ],
   "source": [
    "# uploading\n",
    "# load to database\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# write dataset into database\n",
    "\n",
    "# Import get_engine from sql_functions.py. You will need to restart your kernel and rerun at this point since we changed the module since we first imported it.\n",
    "from sql_functions import get_engine\n",
    "# create a variable called engine using the get_engine function\n",
    "engine = get_engine()\n",
    "\n",
    "import psycopg2\n",
    "\n",
    "table_name = 'skills_20'\n",
    "schema = 'capstone_datacvpro'\n",
    "\n",
    "# Write records stored in a dataframe to SQL database\n",
    "if engine!=None:\n",
    "    try:\n",
    "        df_skills.to_sql(name=table_name, # Name of SQL table variable\n",
    "                        con=engine, # Engine or connection\n",
    "                        schema=schema, # your class schema variable\n",
    "                        if_exists='replace', # Drop the table before inserting new values \n",
    "                        index=False, # Write DataFrame index as a column\n",
    "                        chunksize=5000, # Specify the number of rows in each batch to be written at a time\n",
    "                        method='multi') # Pass multiple values in a single INSERT clause\n",
    "        print(f\"The {table_name} table was imported successfully.\")\n",
    "    # Error handling\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        engine = None\n",
    "else:\n",
    "    print('No engine')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nf_base_capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
